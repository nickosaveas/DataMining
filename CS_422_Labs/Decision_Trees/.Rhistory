train <- train[train$occupation != "?", ]
train <- train[train$native_country != "?", ]
test <- test[test$occupation != "?", ]
test <- test[test$native_country != "?", ]
head(train)
newTrain <- train[train$income == ">50k"]
#newTrain <- train[sample(nrow(train), nrow(test)), ]
summary(newTrain)
newModel <- rpart( income ~ .,method = "class", data = newTrain)
set.seed(1122)
setwd("C:/Users/Nicko/Documents/School/Spring_2018/CS_422_Data_Mining/HW2/")
train <- read.csv("adult-train.csv")
test <- read.csv("adult-test.csv")
# This is a really lame way to clean the date but its effective
train <- train[train$occupation != "?", ]
train <- train[train$native_country != "?", ]
test <- test[test$occupation != "?", ]
test <- test[test$native_country != "?", ]
train
set.seed(1122)
setwd("C:/Users/Nicko/Documents/School/Spring_2018/CS_422_Data_Mining/HW2/")
train <- read.csv("adult-train.csv")
test <- read.csv("adult-test.csv")
# This is a really lame way to clean the date but its effective
train <- train[train$occupation != "?", ]
train <- train[train$native_country != "?", ]
test <- test[test$occupation != "?", ]
test <- test[test$native_country != "?", ]
head(train)
library(rpart)
library(caret)
library(rpart.plot)
library(ROCR)
model <- rpart( income ~ .,method = "class", data = train)
rpart.plot(model, main = "Rpart on Adult Data", type = 4, fallen.leaves = T)
summary(model)
pred <- predict(model, test, type="class")
confusionMatrix(pred, test[, 15])
# ROC curve
pred.rocr <- predict(model, newdata=test, type="prob")[,2]
f.pred <- prediction(pred.rocr, test$income)
f.perf <- performance(f.pred, "tpr", "fpr")
plot(f.perf, colorize=T, lwd=3)
abline(0,1)
auc <- performance(f.pred, measure = "auc")
cat(paste("The area under curve (AUC) for this model is ", round(auc@y.values[[1]], 3)))
cpx=model$cptable[which.min(model$cptable[,"xerror"]), "CP"]
cpx
# ptree <- prune(model, cp=cpx)
# rpart.plot(ptree, main = "Rpart on Adult Data", type = 4, fallen.leaves = T)
# ptree.pred <- predict(ptree, test, type="class")
# confusionMatrix(ptree.pred, test[, 15])
newTrain <- train[train$income == ">50K"]
newTrain <- train[train$income == ">50K", ]
#newTrain <- train[sample(nrow(train), nrow(test)), ]
summary(newTrain)
# newModel <- rpart( income ~ .,method = "class", data = newTrain)
# newPred <- predict(newModel, test, type="class")
# confusionMatrix(newPred, test[, 15])
# summary(newModel)
newTrain <- train[train$income == ">50K", ]
newTrain <- c(newTrain, train[sample(which(train$income == "<=50K"), 7508), ])
#newTrain <- train[sample(nrow(train), nrow(test)), ]
summary(newTrain)
# newModel <- rpart( income ~ .,method = "class", data = newTrain)
# newPred <- predict(newModel, test, type="class")
# confusionMatrix(newPred, test[, 15])
# summary(newModel)
newTrain <- train[train$income == ">50K", ]
newTrain <- train[sample(which(train$income == "<=50K"), 7508), ]
#newTrain <- train[sample(nrow(train), nrow(test)), ]
summary(newTrain)
# newModel <- rpart( income ~ .,method = "class", data = newTrain)
# newPred <- predict(newModel, test, type="class")
# confusionMatrix(newPred, test[, 15])
# summary(newModel)
newTrainA <- train[train$income == ">50K", ]
newTrainB <- train[sample(which(train$income == "<=50K"), 7508), ]
newTrain <- c(newTrainA, newTrainB)
#newTrain <- train[sample(nrow(train), nrow(test)), ]
summary(newTrain)
# newModel <- rpart( income ~ .,method = "class", data = newTrain)
# newPred <- predict(newModel, test, type="class")
# confusionMatrix(newPred, test[, 15])
# summary(newModel)
newTrainA <- train[train$income == ">50K", ]
newTrainB <- train[sample(which(train$income == "<=50K"), 7508), ]
newTrain <- rbind(newTrainA, newTrainB)
#newTrain <- train[sample(nrow(train), nrow(test)), ]
summary(newTrain)
# newModel <- rpart( income ~ .,method = "class", data = newTrain)
# newPred <- predict(newModel, test, type="class")
# confusionMatrix(newPred, test[, 15])
# summary(newModel)
# Get all observations of negative class
newTrainA <- train[train$income == ">50K", ]
# Get the observations with the positive class but only the number of rows in newTrainA
newTrainB <- train[sample(which(train$income == "<=50K"), nrow(newTrainA)), ]
newTrain <- rbind(newTrainA, newTrainB)
summary(newTrain)
newModel <- rpart( income ~ .,method = "class", data = newTrain)
newPred <- predict(newModel, test, type="class")
confusionMatrix(newPred, test[, 15])
summary(newModel)
# Get all observations of negative class
newTrainA <- train[train$income == ">50K", ]
# Get the observations with the positive class but only the number of rows in newTrainA
newTrainB <- train[sample(which(train$income == "<=50K"), nrow(newTrainA)), ]
newTrain <- rbind(newTrainA, newTrainB)
newModel <- rpart( income ~ .,method = "class", data = newTrain)
newPred <- predict(newModel, test, type="class")
confusionMatrix(newPred, test[, 15])
# ROC curve
pred.rocr <- predict(newModel, newdata=test, type="prob")[,2]
f.pred <- prediction(pred.rocr, test$income)
f.perf <- performance(f.pred, "tpr", "fpr")
plot(f.perf, colorize=T, lwd=3)
abline(0,1)
auc <- performance(f.pred, measure = "auc")
cat(paste("The area under curve (AUC) for this model is ", round(auc@y.values[[1]], 3)))
library(rpart)
library(caret)
library(rpart.plot)
library(randomForest)
setwd("/home/vkg/IIT/CS422/lectures/lecture-5")
library(rpart)
library(caret)
library(rpart.plot)
library(randomForest)
setwd("C:/Users/Nicko/Documents/School/Spring_2018/CS_422_Data_Mining/Lecture5/")
set.seed(1122)
df <- read.csv("german_credit.csv", sep=",", comment.char = "#")
# Note: You can also read the file directly using a URL:
# df <- read.csv("https://sites.google.com/site/pocketecoworld/german_credit.csv")
df$Creditability <- as.factor(df$Creditability)
indx <- sample(1:nrow(df), 200)
train <- df[-indx, ]
test <- df[indx, ]
cat("Training dataset class label distribution")
table(train$Creditability)
cat("\nTest dataset class label distribution")
table(test$Creditability)
model <- rpart(Creditability ~ ., data=train)
pred <- predict(model, test, type="class")
confusionMatrix(pred, as.factor(test$Creditability))
rm(model, pred)
model <- randomForest(Creditability ~ ., data=train)
pred <- predict(model, test, type="class")
confusionMatrix(pred, as.factor(test$Creditability))
print(model)
rm(model, pred)
model <- randomForest(Creditability ~ ., data=train, mtry=6)
pred <- predict(model, test, type="class")
confusionMatrix(pred, as.factor(test$Creditability))
print(model)
plot(model, main="Random Forest on German Credit Data")
legend("topright", colnames(model$err.rate), col=1:3, cex = 0.8, fill=1:3)
model <- randomForest(income ~ ., data=train)
knitr::opts_chunk$set(echo = TRUE)
set.seed(1122)
setwd("C:/Users/Nicko/Documents/School/Spring_2018/CS_422_Data_Mining/HW2/")
train <- read.csv("adult-train.csv")
test <- read.csv("adult-test.csv")
# This is a really lame way to clean the date but its effective
train <- train[train$occupation != "?", ]
train <- train[train$native_country != "?", ]
test <- test[test$occupation != "?", ]
test <- test[test$native_country != "?", ]
head(train)
library(rpart)
library(caret)
library(rpart.plot)
library(ROCR)
model <- rpart( income ~ .,method = "class", data = train)
rpart.plot(model, main = "Rpart on Adult Data", type = 4, fallen.leaves = T)
summary(model)
pred <- predict(model, test, type="class")
confusionMatrix(pred, test[, 15])
# ROC curve
pred.rocr <- predict(model, newdata=test, type="prob")[,2]
f.pred <- prediction(pred.rocr, test$income)
f.perf <- performance(f.pred, "tpr", "fpr")
plot(f.perf, colorize=T, lwd=3)
abline(0,1)
auc <- performance(f.pred, measure = "auc")
cat(paste("The area under curve (AUC) for this model is ", round(auc@y.values[[1]], 3)))
cpx=model$cptable[which.min(model$cptable[,"xerror"]), "CP"]
cpx
# ptree <- prune(model, cp=cpx)
# rpart.plot(ptree, main = "Rpart on Adult Data", type = 4, fallen.leaves = T)
# ptree.pred <- predict(ptree, test, type="class")
# confusionMatrix(ptree.pred, test[, 15])
# Get all observations of negative class
newTrainA <- train[train$income == ">50K", ]
# Get the observations with the positive class but only the number of rows in newTrainA
newTrainB <- train[sample(which(train$income == "<=50K"), nrow(newTrainA)), ]
newTrain <- rbind(newTrainA, newTrainB)
newModel <- rpart( income ~ .,method = "class", data = newTrain)
newPred <- predict(newModel, test, type="class")
confusionMatrix(newPred, test[, 15])
# ROC curve
pred.rocr <- predict(newModel, newdata=test, type="prob")[,2]
f.pred <- prediction(pred.rocr, test$income)
f.perf <- performance(f.pred, "tpr", "fpr")
plot(f.perf, colorize=T, lwd=3)
abline(0,1)
auc <- performance(f.pred, measure = "auc")
cat(paste("The area under curve (AUC) for this model is ", round(auc@y.values[[1]], 3)))
model <- randomForest(income ~ ., data=train)
knitr::opts_chunk$set(echo = TRUE)
set.seed(1122)
setwd("C:/Users/Nicko/Documents/School/Spring_2018/CS_422_Data_Mining/HW2/")
train <- read.csv("adult-train.csv")
test <- read.csv("adult-test.csv")
# This is a really lame way to clean the date but its effective
train <- train[train$occupation != "?", ]
train <- train[train$native_country != "?", ]
test <- test[test$occupation != "?", ]
test <- test[test$native_country != "?", ]
head(train)
library(rpart)
library(caret)
library(rpart.plot)
library(ROCR)
model <- rpart( income ~ .,method = "class", data = train)
rpart.plot(model, main = "Rpart on Adult Data", type = 4, fallen.leaves = T)
summary(model)
pred <- predict(model, test, type="class")
confusionMatrix(pred, test[, 15])
# ROC curve
pred.rocr <- predict(model, newdata=test, type="prob")[,2]
f.pred <- prediction(pred.rocr, test$income)
f.perf <- performance(f.pred, "tpr", "fpr")
plot(f.perf, colorize=T, lwd=3)
abline(0,1)
auc <- performance(f.pred, measure = "auc")
cat(paste("The area under curve (AUC) for this model is ", round(auc@y.values[[1]], 3)))
cpx=model$cptable[which.min(model$cptable[,"xerror"]), "CP"]
cpx
# ptree <- prune(model, cp=cpx)
# rpart.plot(ptree, main = "Rpart on Adult Data", type = 4, fallen.leaves = T)
# ptree.pred <- predict(ptree, test, type="class")
# confusionMatrix(ptree.pred, test[, 15])
# Get all observations of negative class
newTrainA <- train[train$income == ">50K", ]
# Get the observations with the positive class but only the number of rows in newTrainA
newTrainB <- train[sample(which(train$income == "<=50K"), nrow(newTrainA)), ]
newTrain <- rbind(newTrainA, newTrainB)
newModel <- rpart( income ~ .,method = "class", data = newTrain)
newPred <- predict(newModel, test, type="class")
confusionMatrix(newPred, test[, 15])
# ROC curve
pred.rocr <- predict(newModel, newdata=test, type="prob")[,2]
f.pred <- prediction(pred.rocr, test$income)
f.perf <- performance(f.pred, "tpr", "fpr")
plot(f.perf, colorize=T, lwd=3)
abline(0,1)
auc <- performance(f.pred, measure = "auc")
cat(paste("The area under curve (AUC) for this model is ", round(auc@y.values[[1]], 3)))
model <- randomForest(income ~ ., data=train)
library(randomForest)
model <- randomForest(income ~ ., data=train)
pred <- predict(model, test, type="class")
confusionMatrix(pred, test[, 15])
install.packages("randomForest")
install.packages("randomForest")
knitr::opts_chunk$set(echo = TRUE)
set.seed(1122)
setwd("C:/Users/Nicko/Documents/School/Spring_2018/CS_422_Data_Mining/HW2/")
train <- read.csv("adult-train.csv")
test <- read.csv("adult-test.csv")
# This is a really lame way to clean the date but its effective
train <- train[train$occupation != "?", ]
train <- train[train$native_country != "?", ]
test <- test[test$occupation != "?", ]
test <- test[test$native_country != "?", ]
head(train)
library(rpart)
library(caret)
library(rpart.plot)
library(ROCR)
model <- rpart( income ~ .,method = "class", data = train)
rpart.plot(model, main = "Rpart on Adult Data", type = 4, fallen.leaves = T)
summary(model)
pred <- predict(model, test, type="class")
confusionMatrix(pred, test[, 15])
# ROC curve
pred.rocr <- predict(model, newdata=test, type="prob")[,2]
f.pred <- prediction(pred.rocr, test$income)
f.perf <- performance(f.pred, "tpr", "fpr")
plot(f.perf, colorize=T, lwd=3)
abline(0,1)
auc <- performance(f.pred, measure = "auc")
cat(paste("The area under curve (AUC) for this model is ", round(auc@y.values[[1]], 3)))
cpx=model$cptable[which.min(model$cptable[,"xerror"]), "CP"]
cpx
# ptree <- prune(model, cp=cpx)
# rpart.plot(ptree, main = "Rpart on Adult Data", type = 4, fallen.leaves = T)
# ptree.pred <- predict(ptree, test, type="class")
# confusionMatrix(ptree.pred, test[, 15])
# Get all observations of negative class
newTrainA <- train[train$income == ">50K", ]
# Get the observations with the positive class but only the number of rows in newTrainA
newTrainB <- train[sample(which(train$income == "<=50K"), nrow(newTrainA)), ]
newTrain <- rbind(newTrainA, newTrainB)
newModel <- rpart( income ~ .,method = "class", data = newTrain)
newPred <- predict(newModel, test, type="class")
confusionMatrix(newPred, test[, 15])
# ROC curve
pred.rocr <- predict(newModel, newdata=test, type="prob")[,2]
f.pred <- prediction(pred.rocr, test$income)
f.perf <- performance(f.pred, "tpr", "fpr")
plot(f.perf, colorize=T, lwd=3)
abline(0,1)
auc <- performance(f.pred, measure = "auc")
cat(paste("The area under curve (AUC) for this model is ", round(auc@y.values[[1]], 3)))
library(randomForest)
model <- randomForest(income ~ ., data=train)
pred <- predict(model, test, type="class")
confusionMatrix(pred, test[, 15])
summary(test)
varImpPlot(model)
library(randomForest)
model <- randomForest(income ~ ., data=train, importance=TRUE)
pred <- predict(model, test, type="class")
confusionMatrix(pred, test[, 15])
library(randomForest)
set.seed(1122)
model <- randomForest(income ~ ., data=train, importance=TRUE)
pred <- predict(model, test, type="class")
confusionMatrix(pred, test[, 15])
summary(test)
varImpPlot(model)
print(model)
print(model)
mtry <- tuneRF(train, train$income, ntreeTry=500, stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
mtry <- tuneRF(train[1,14], train$income, ntreeTry=500, stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
mtry <- tuneRF(train[, 1:14], train$income, ntreeTry=500, stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
mtry <- tuneRF(train[, 1:14], train$income, ntreeTry=500, stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
print(mtry)
set.seed(1122)
mtry <- tuneRF(train[, 1:14], train$income, ntreeTry=500, stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
print(mtry)
set.seed(1122)
mtry <- tuneRF(train[, 1:14], train$income, ntreeTry=500, stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
print(mtry)
library(randomForest)
set.seed(1122)
model <- randomForest(income ~ ., data=train, importance=TRUE, mtry=2)
pred <- predict(model, test, type="class")
confusionMatrix(pred, test[, 15])
varImpPlot(model)
install.packages("arules")
dataFrame <- read.transactions("groceries.csv")
dataFrame <- read.csv("groceries.csv")
trans <- as.matrix(read.csv("groceries.csv", header=T, sep=" "))
trans <- as.matrix(read.csv("groceries.csv"))
trans <- as.matrix(read.csv("groceries.csv"))
rules <- apriori(trans)
install.packages("apriori")
install.packages("arules")
install.packages("apriori")
trans <- as.matrix(read.csv("groceries.csv"))
rules <- apriori(trans)
install.packages("arules", dependencies = TRUE)
library(arules)
trans <- as.matrix(read.csv("groceries.csv"))
rules <- apriori(trans)
library(arules)
trans <- read.transactions("groceries.csv")
rules <- apriori(trans)
rules < apriori(trans, parameter = (supp = 0.01))
rules < apriori(trans, parameter = list(supp = 0.01))
rules < apriori(trans, parameter = list(supp = 0.0001))
rules < apriori(trans, parameter = list(supp = 0.001))
rules < apriori(trans, parameter = "supp = 0.001")
rules < apriori(trans, parameter = supp = 0.001)
rules < apriori(trans, parameter = list(supp=0.001, conf=0.8))
rules < apriori(filter(trans), parameter = list(supp=0.001, conf=0.8))
rules < apriori(trans, parameter = list(supp=0.001, conf=0.8))
rules < apriori(trans, parameter = list(supp=0.0005, conf=0.8))
rules < apriori(trans, parameter = list(supp=0.0008, conf=0.8))
rules < apriori(trans, parameter = list(supp=0.0007, conf=0.8))
rules < apriori(trans, parameter = list(supp=0.00065, conf=0.8))
rules < apriori(trans, parameter = list(supp=0.0006, conf=0.8))
rules < apriori(trans, parameter = list(supp=0.00062, conf=0.8))
rules < apriori(trans, parameter = list(supp=0.00061, conf=0.8))
rules < apriori(trans, parameter = list(supp=0.0006, conf=0.8))
inspect(head(rules, by="support"))
inspect(head(rules, by="confidence"))
inspect(head(rules, by="support"))
inspect(head(rules, by="confidence"))
rules < apriori(trans, parameter = list(supp=0.0006, conf=0.8))
rules <- apriori(trans, parameter = list(supp=0.0006, conf=0.8))
inspect(head(rules, by="support"))
inspect(head(rules, by="confidence"))
inspect(head(rules, by="-confidence"))
inspect(head(rules, by="confidence"))
inspect(head(rules, by="-confidence"))
inspect(head(rules, by="confidence"))
inspect(head(reverse((rules, by="confidence")))
inspect(head(reverse((rules, by="confidence"))))
inspect(head(reverse(rules), by="confidence"))
rules <- sort(rules, decreasing = TRUE, na.last = NA, by = "support")
inspect(head(rules))
rules <- sort(rules, decreasing = FALSE, na.last = NA, by = "support")
inspect(head(rules))
rules <- sort(rules, decreasing = FALSE, na.last = NA, by = "support")
inspect(rules[,5])
rules <- sort(rules, decreasing = FALSE, na.last = NA, by = "support")
inspect(rules[5, ])
rules <- sort(rules, decreasing = FALSE, na.last = NA, by = "support")
inspect(rules[1:5])
rules <- sort(rules, decreasing = TRUE, na.last = NA, by = "support")
inspect(rules[1:5])
rules <- sort(rules, decreasing = TRUE, na.last = NA, by = "confidence")
inspect(rules[1:5])
rules <- sort(rules, decreasing = FALSE, na.last = NA, by = "confidence")
inspect(rules[1:5])
rules <- apriori(trans, parameter = list(supp=0.0006))
rules <- sort(trans, decreasing = TRUE, na.last = NA, by = "support")
head(trans)
head(rules)
trans
knitr::opts_chunk$set(echo = TRUE)
set.seed(1122)
setwd("C:/Users/Nicko/Documents/School/Spring_2018/CS_422_Data_Mining/HW2/")
train <- read.csv("adult-train.csv")
test <- read.csv("adult-test.csv")
# This is a really lame way to clean the date but its effective
train <- train[train$occupation != "?", ]
train <- train[train$native_country != "?", ]
test <- test[test$occupation != "?", ]
test <- test[test$native_country != "?", ]
head(train)
library(rpart)
library(caret)
library(rpart.plot)
library(ROCR)
model <- rpart( income ~ .,method = "class", data = train)
rpart.plot(model, main = "Rpart on Adult Data", type = 4, fallen.leaves = T)
summary(model)
pred <- predict(model, test, type="class")
confusionMatrix(pred, test[, 15])
# ROC curve
pred.rocr <- predict(model, newdata=test, type="prob")[,2]
f.pred <- prediction(pred.rocr, test$income)
f.perf <- performance(f.pred, "tpr", "fpr")
plot(f.perf, colorize=T, lwd=3)
abline(0,1)
auc <- performance(f.pred, measure = "auc")
cat(paste("The area under curve (AUC) for this model is ", round(auc@y.values[[1]], 3)))
cpx=model$cptable[which.min(model$cptable[,"xerror"]), "CP"]
cpx
# ptree <- prune(model, cp=cpx)
# rpart.plot(ptree, main = "Rpart on Adult Data", type = 4, fallen.leaves = T)
# ptree.pred <- predict(ptree, test, type="class")
# confusionMatrix(ptree.pred, test[, 15])
# Get all observations of negative class
newTrainA <- train[train$income == ">50K", ]
# Get the observations with the positive class but only the number of rows in newTrainA
newTrainB <- train[sample(which(train$income == "<=50K"), nrow(newTrainA)), ]
newTrain <- rbind(newTrainA, newTrainB)
newModel <- rpart( income ~ .,method = "class", data = newTrain)
newPred <- predict(newModel, test, type="class")
confusionMatrix(newPred, test[, 15])
# ROC curve
pred.rocr <- predict(newModel, newdata=test, type="prob")[,2]
f.pred <- prediction(pred.rocr, test$income)
f.perf <- performance(f.pred, "tpr", "fpr")
plot(f.perf, colorize=T, lwd=3)
abline(0,1)
auc <- performance(f.pred, measure = "auc")
cat(paste("The area under curve (AUC) for this model is ", round(auc@y.values[[1]], 3)))
library(randomForest)
set.seed(1122)
model <- randomForest(income ~ ., data=train, importance=TRUE)
pred <- predict(model, test, type="class")
confusionMatrix(pred, test[, 15])
summary(test)
varImpPlot(model)
print(model)
set.seed(1122)
mtry <- tuneRF(train[, 1:14], train$income, ntreeTry=500, stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
print(mtry)
library(randomForest)
set.seed(1122)
model <- randomForest(income ~ ., data=train, importance=TRUE, mtry=2)
pred <- predict(model, test, type="class")
confusionMatrix(pred, test[, 15])
varImpPlot(model)
library(arules)
trans <- read.transactions("groceries.csv")
rules <- apriori(trans)
rules <- apriori(trans, parameter = list(supp=0.0006))
trans
rules <- sort(rules, decreasing = TRUE, na.last = NA, by = "support")
inspect(rules[1:5])
rules <- sort(rules, decreasing = TRUE, na.last = NA, by = "confidence")
inspect(rules[1:5])
rules <- sort(rules, decreasing = FALSE, na.last = NA, by = "support")
inspect(rules[1:5])
rules <- sort(rules, decreasing = FALSE, na.last = NA, by = "confidence")
inspect(rules[1:5])
rules <- sort(rules, decreasing = FALSE, na.last = NA, by = "count")
inspect(rules[1:5])
rules <- sort(rules, decreasing = FALSE, na.last = NA, by = "confidence")
inspect(rules[1:5])
rules <- sort(rules, decreasing = TRUE, na.last = NA, by = "count")
inspect(rules[1:5])
rules <- sort(rules, decreasing = TRUE, na.last = NA, by = "support")
inspect(rules[1:5])
